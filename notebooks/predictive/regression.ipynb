{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDSI Advanced Machine Learning Applications\n",
    "\n",
    "**Student: Ivan Cheung**\n",
    "\n",
    "**Assignment: AT2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "df_train = pd.read_csv('../../data/raw/sales_train.csv')\n",
    "df_items = pd.read_csv('../../data/raw/items_weekly_sell_prices.csv')\n",
    "df_cal = pd.read_csv('../../data/raw/calendar.csv')\n",
    "df_events = pd.read_csv('../../data/raw/calendar_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis:\n",
    "\n",
    "1) Identify columns of interest\n",
    "\n",
    "2) Identify how columns should be encoded for the model:\n",
    "    - Categorical columns with large volume of unique values: Label Encoding\n",
    "    - Categorical columns with low volume of unique values: One Hot Encoding\n",
    "    - numerical columns: StandardScalar\n",
    "    - Date column: no encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1532</th>\n",
       "      <th>d_1533</th>\n",
       "      <th>d_1534</th>\n",
       "      <th>d_1535</th>\n",
       "      <th>d_1536</th>\n",
       "      <th>d_1537</th>\n",
       "      <th>d_1538</th>\n",
       "      <th>d_1539</th>\n",
       "      <th>d_1540</th>\n",
       "      <th>d_1541</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1547 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1532  d_1533  d_1534  d_1535  d_1536  \\\n",
       "0       CA    0    0    0    0  ...       1       1       1       0       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       0       0       1       0       0   \n",
       "3       CA    0    0    0    0  ...       8       2       0       8       2   \n",
       "4       CA    0    0    0    0  ...       2       0       1       3       2   \n",
       "\n",
       "   d_1537  d_1538  d_1539  d_1540  d_1541  \n",
       "0       0       1       0       0       1  \n",
       "1       0       0       0       1       0  \n",
       "2       0       0       0       0       0  \n",
       "3       3       1       1       3       8  \n",
       "4       1       1       2       2       3  \n",
       "\n",
       "[5 rows x 1547 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6841121 entries, 0 to 6841120\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   store_id    object \n",
      " 1   item_id     object \n",
      " 2   wm_yr_wk    int64  \n",
      " 3   sell_price  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 208.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1969 entries, 0 to 1968\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   date      1969 non-null   object\n",
      " 1   wm_yr_wk  1969 non-null   int64 \n",
      " 2   d         1969 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 46.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 167 entries, 0 to 166\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   date        167 non-null    object\n",
      " 1   event_name  167 non-null    object\n",
      " 2   event_type  167 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove variables to recover memory\n",
    "del(df_cal)\n",
    "del(df_events)\n",
    "del(df_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature construction:\n",
    "\n",
    "1) merge item sales with sale price to calculate revenue per observation in df_train\n",
    "2) pivot out calendar events and append calendar events to df_train table\n",
    "3) clean date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        HOBBIES_1_001_CA_1_evaluation\n",
       "1        HOBBIES_1_002_CA_1_evaluation\n",
       "2        HOBBIES_1_003_CA_1_evaluation\n",
       "3        HOBBIES_1_004_CA_1_evaluation\n",
       "4        HOBBIES_1_005_CA_1_evaluation\n",
       "                     ...              \n",
       "30485      FOODS_3_823_WI_3_evaluation\n",
       "30486      FOODS_3_824_WI_3_evaluation\n",
       "30487      FOODS_3_825_WI_3_evaluation\n",
       "30488      FOODS_3_826_WI_3_evaluation\n",
       "30489      FOODS_3_827_WI_3_evaluation\n",
       "Name: id, Length: 30490, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1: pop id, this data is not needed\n",
    "df_train.pop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2: apply melt to convert all date columns into a single column\n",
    "df_train = pd.melt(df_train, id_vars=['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'd', value_name = 'items_sold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(d):\n",
    "    diff = pd.to_datetime(d) - pd.to_datetime(\"2011-01-01\")\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. merge with calendar table to bring in wm_yr_wk col\n",
    "df_cal = pd.read_csv('../../data/raw/calendar.csv')\n",
    "df_cal['datediff'] = df_cal['date'].apply(convert_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>d</th>\n",
       "      <th>datediff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>d_5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>11620</td>\n",
       "      <td>d_1965</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>11620</td>\n",
       "      <td>d_1966</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>2016-06-17</td>\n",
       "      <td>11620</td>\n",
       "      <td>d_1967</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>2016-06-18</td>\n",
       "      <td>11621</td>\n",
       "      <td>d_1968</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1969 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  wm_yr_wk       d  datediff\n",
       "0     2011-01-29     11101     d_1        28\n",
       "1     2011-01-30     11101     d_2        29\n",
       "2     2011-01-31     11101     d_3        30\n",
       "3     2011-02-01     11101     d_4        31\n",
       "4     2011-02-02     11101     d_5        32\n",
       "...          ...       ...     ...       ...\n",
       "1964  2016-06-15     11620  d_1965      1992\n",
       "1965  2016-06-16     11620  d_1966      1993\n",
       "1966  2016-06-17     11620  d_1967      1994\n",
       "1967  2016-06-18     11621  d_1968      1995\n",
       "1968  2016-06-19     11621  d_1969      1996\n",
       "\n",
       "[1969 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\AMLA\\amla2023_at2\\notebooks\\predictive\\regression.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AMLA/amla2023_at2/notebooks/predictive/regression.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(df_train, df_cal, on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39md\u001b[39;49m\u001b[39m'\u001b[39;49m, how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AMLA/amla2023_at2/notebooks/predictive/regression.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_train\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AMLA/amla2023_at2/notebooks/predictive/regression.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdel\u001b[39;00m(df_cal)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:162\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    146\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    147\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m    148\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    149\u001b[0m         left,\n\u001b[0;32m    150\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:809\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n\u001b[0;32m    807\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m--> 809\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_info()\n\u001b[0;32m    811\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    812\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    813\u001b[0m )\n\u001b[0;32m    814\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1065\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     join_index, right_indexer, left_indexer \u001b[39m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1062\u001b[0m         right_ax, left_ax, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys, sort\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort\n\u001b[0;32m   1063\u001b[0m     )\n\u001b[0;32m   1064\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1065\u001b[0m     (left_indexer, right_indexer) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_join_indexers()\n\u001b[0;32m   1067\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_index:\n\u001b[0;32m   1068\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1038\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_join_indexers\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp], npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mintp]]:\n\u001b[0;32m   1037\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"return the join indexers\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m     \u001b[39mreturn\u001b[39;00m get_join_indexers(\n\u001b[0;32m   1039\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft_join_keys, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright_join_keys, sort\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msort, how\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow\n\u001b[0;32m   1040\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1665\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[39m# get left & right join labels and num. of levels at each location\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m mapped \u001b[39m=\u001b[39m (\n\u001b[0;32m   1662\u001b[0m     _factorize_keys(left_keys[n], right_keys[n], sort\u001b[39m=\u001b[39msort, how\u001b[39m=\u001b[39mhow)\n\u001b[0;32m   1663\u001b[0m     \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(left_keys))\n\u001b[0;32m   1664\u001b[0m )\n\u001b[1;32m-> 1665\u001b[0m zipped \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49mmapped)\n\u001b[0;32m   1666\u001b[0m llab, rlab, shape \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m zipped)\n\u001b[0;32m   1668\u001b[0m \u001b[39m# get flat i8 keys from label lists\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1662\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1658\u001b[0m         \u001b[39mreturn\u001b[39;00m _get_no_sort_one_missing_indexer(left_n, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1660\u001b[0m \u001b[39m# get left & right join labels and num. of levels at each location\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m mapped \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1662\u001b[0m     _factorize_keys(left_keys[n], right_keys[n], sort\u001b[39m=\u001b[39;49msort, how\u001b[39m=\u001b[39;49mhow)\n\u001b[0;32m   1663\u001b[0m     \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(left_keys))\n\u001b[0;32m   1664\u001b[0m )\n\u001b[0;32m   1665\u001b[0m zipped \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mmapped)\n\u001b[0;32m   1666\u001b[0m llab, rlab, shape \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m zipped)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2443\u001b[0m, in \u001b[0;36m_factorize_keys\u001b[1;34m(lk, rk, sort, how)\u001b[0m\n\u001b[0;32m   2438\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2439\u001b[0m     \u001b[39m# Argument 1 to \"factorize\" of \"ObjectFactorizer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   2440\u001b[0m     \u001b[39m# \"Union[ndarray[Any, dtype[signedinteger[_64Bit]]],\u001b[39;00m\n\u001b[0;32m   2441\u001b[0m     \u001b[39m# ndarray[Any, dtype[object_]]]\"; expected \"ndarray[Any, dtype[object_]]\"\u001b[39;00m\n\u001b[0;32m   2442\u001b[0m     llab \u001b[39m=\u001b[39m rizer\u001b[39m.\u001b[39mfactorize(lk)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m-> 2443\u001b[0m     rlab \u001b[39m=\u001b[39m rizer\u001b[39m.\u001b[39;49mfactorize(rk)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2444\u001b[0m \u001b[39massert\u001b[39;00m llab\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mintp), llab\u001b[39m.\u001b[39mdtype\n\u001b[0;32m   2445\u001b[0m \u001b[39massert\u001b[39;00m rlab\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mintp), rlab\u001b[39m.\u001b[39mdtype\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_train = pd.merge(df_train, df_cal, on='d', how='left')\n",
    "df_train.pop('d')\n",
    "del(df_cal)\n",
    "print('remove unneeded column and table to recover memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove unneeded column and table to recover memory\n"
     ]
    }
   ],
   "source": [
    "## 4. merge with items sale prices to calculate revenue\n",
    "df_items = pd.read_csv('../../data/raw/items_weekly_sell_prices.csv')\n",
    "df_train = pd.merge(df_train, df_items, left_on = ['store_id', 'item_id', 'wm_yr_wk'], right_on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "\n",
    "df_train.pop('wm_yr_wk')\n",
    "del(df_items)\n",
    "print('remove unneeded column and table to recover memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove unneeded column to recover memory\n"
     ]
    }
   ],
   "source": [
    "## 5. calculate revenue and drop item sales and sell price columns\n",
    "df_train['items_sold'] = df_train['items_sold'].fillna(0)\n",
    "df_train['sell_price'] = df_train['sell_price'].fillna(0)\n",
    "\n",
    "df_train['revenue'] = df_train['items_sold'] * df_train['sell_price']\n",
    "df_train.pop('items_sold')\n",
    "df_train.pop('sell_price')\n",
    "print('remove unneeded column to recover memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datediff</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46985085</th>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>2015-04-18</td>\n",
       "      <td>1568</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46985086</th>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>2015-04-18</td>\n",
       "      <td>1568</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46985087</th>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>2015-04-18</td>\n",
       "      <td>1568</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46985088</th>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>2015-04-18</td>\n",
       "      <td>1568</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46985089</th>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>2015-04-18</td>\n",
       "      <td>1568</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46985090 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                item_id    dept_id   cat_id store_id state_id        date  \\\n",
       "0         HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA  2011-01-29   \n",
       "1         HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA  2011-01-29   \n",
       "2         HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA  2011-01-29   \n",
       "3         HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA  2011-01-29   \n",
       "4         HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA  2011-01-29   \n",
       "...                 ...        ...      ...      ...      ...         ...   \n",
       "46985085    FOODS_3_823    FOODS_3    FOODS     WI_3       WI  2015-04-18   \n",
       "46985086    FOODS_3_824    FOODS_3    FOODS     WI_3       WI  2015-04-18   \n",
       "46985087    FOODS_3_825    FOODS_3    FOODS     WI_3       WI  2015-04-18   \n",
       "46985088    FOODS_3_826    FOODS_3    FOODS     WI_3       WI  2015-04-18   \n",
       "46985089    FOODS_3_827    FOODS_3    FOODS     WI_3       WI  2015-04-18   \n",
       "\n",
       "          datediff  revenue  \n",
       "0               28     0.00  \n",
       "1               28     0.00  \n",
       "2               28     0.00  \n",
       "3               28     0.00  \n",
       "4               28     0.00  \n",
       "...            ...      ...  \n",
       "46985085      1568     5.76  \n",
       "46985086      1568     0.00  \n",
       "46985087      1568     0.00  \n",
       "46985088      1568     0.00  \n",
       "46985089      1568     3.00  \n",
       "\n",
       "[46985090 rows x 8 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>event_cultural</th>\n",
       "      <th>event_national</th>\n",
       "      <th>event_religious</th>\n",
       "      <th>event_sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-02-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-02-21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-03-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-03-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2016-05-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2016-06-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  event_cultural  event_national  event_religious  event_sport\n",
       "0    2011-02-06               0               0                0            1\n",
       "1    2011-02-14               1               0                0            0\n",
       "2    2011-02-21               0               1                0            0\n",
       "3    2011-03-09               0               0                1            0\n",
       "4    2011-03-16               0               0                1            0\n",
       "..          ...             ...             ...              ...          ...\n",
       "157  2016-05-08               1               0                0            0\n",
       "158  2016-05-30               0               1                0            0\n",
       "159  2016-06-02               0               0                0            1\n",
       "160  2016-06-07               0               0                1            0\n",
       "161  2016-06-19               1               0                0            1\n",
       "\n",
       "[162 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6. expand calendar events to count the number of holidays on a given date\n",
    "df_events = pd.read_csv('../../data/raw/calendar_events.csv')\n",
    "\n",
    "df_events = pd.pivot_table(df_events, index='date', values='event_name', columns='event_type', aggfunc='count', fill_value= 0)\n",
    "df_events = df_events.rename_axis(columns= None).reset_index()\n",
    "\n",
    "### rename cols for better readbility\n",
    "df_events = df_events.rename(columns={\"Cultural\": \"event_cultural\", \"National\": \"event_national\", \"Religious\": \"event_religious\", \"Sporting\": \"event_sport\"})\n",
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. merge df_train with cal events\n",
    "df_train = pd.merge(df_train, df_events, left_on = ['date'], right_on = ['date'], how = 'left')\n",
    "df_train['event_cultural'] = df_train['event_cultural'].fillna(0).astype('int64')\n",
    "df_train['event_national'] = df_train['event_national'].fillna(0).astype('int64')\n",
    "df_train['event_religious'] = df_train['event_religious'].fillna(0).astype('int64')\n",
    "df_train['event_sport'] = df_train['event_sport'].fillna(0).astype('int64')\n",
    "del(df_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove column to recover memory\n"
     ]
    }
   ],
   "source": [
    "df_train.pop('date')\n",
    "print('remove column to recover memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>datediff</th>\n",
       "      <th>revenue</th>\n",
       "      <th>event_cultural</th>\n",
       "      <th>event_national</th>\n",
       "      <th>event_religious</th>\n",
       "      <th>event_sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id    dept_id   cat_id store_id state_id  datediff  revenue  \\\n",
       "0  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA        28      0.0   \n",
       "1  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA        28      0.0   \n",
       "2  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA        28      0.0   \n",
       "3  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA        28      0.0   \n",
       "4  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA        28      0.0   \n",
       "\n",
       "   event_cultural  event_national  event_religious  event_sport  \n",
       "0               0               0                0            0  \n",
       "1               0               0                0            0  \n",
       "2               0               0                0            0  \n",
       "3               0               0                0            0  \n",
       "4               0               0                0            0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet('../../data/processed/df_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet('../../data/processed/df_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46985090 entries, 0 to 46985089\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Dtype  \n",
      "---  ------           -----  \n",
      " 0   item_id          object \n",
      " 1   dept_id          object \n",
      " 2   cat_id           object \n",
      " 3   store_id         object \n",
      " 4   state_id         object \n",
      " 5   datediff         int64  \n",
      " 6   revenue          float64\n",
      " 7   event_cultural   int64  \n",
      " 8   event_national   int64  \n",
      " 9   event_religious  int64  \n",
      " 10  event_sport      int64  \n",
      "dtypes: float64(1), int64(5), object(5)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Swapping out column type to reduce memory usage\n",
    "df_train['cat_id'] = df_train['cat_id'].astype(\"category\")\n",
    "df_train['dept_id'] = df_train['dept_id'].astype(\"category\")\n",
    "df_train['store_id'] = df_train['store_id'].astype(\"category\")\n",
    "df_train['state_id'] = df_train['state_id'].astype(\"category\")\n",
    "df_train['item_id'] = df_train['item_id'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## swapping out int for unsigned\n",
    "df_train['datediff'] = pd.to_numeric(df_train['datediff'], downcast='unsigned')\n",
    "df_train['event_cultural'] = pd.to_numeric(df_train['event_cultural'], downcast='unsigned')\n",
    "df_train['event_national'] = pd.to_numeric(df_train['event_national'], downcast='unsigned')\n",
    "df_train['event_religious'] = pd.to_numeric(df_train['event_religious'], downcast='unsigned')\n",
    "df_train['event_sport'] = pd.to_numeric(df_train['event_sport'], downcast='unsigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46985090 entries, 0 to 46985089\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Dtype   \n",
      "---  ------           -----   \n",
      " 0   item_id          category\n",
      " 1   dept_id          category\n",
      " 2   cat_id           category\n",
      " 3   store_id         category\n",
      " 4   state_id         category\n",
      " 5   datediff         uint16  \n",
      " 6   revenue          float64 \n",
      " 7   event_cultural   uint8   \n",
      " 8   event_national   uint8   \n",
      " 9   event_religious  uint8   \n",
      " 10  event_sport      uint8   \n",
      "dtypes: category(5), float64(1), uint16(1), uint8(4)\n",
      "memory usage: 896.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train['item_id'] 3049\n",
      "df_train['dept_id'] 7\n",
      "df_train['cat_id'] 3\n",
      "df_train['store_id'] 10\n",
      "df_train['state_id'] 3\n"
     ]
    }
   ],
   "source": [
    "print(\"df_train['item_id'] \" + str(df_train['item_id'].nunique()))\n",
    "print(\"df_train['dept_id'] \" + str(df_train['dept_id'].nunique()))\n",
    "print(\"df_train['cat_id'] \" + str(df_train['cat_id'].nunique()))\n",
    "print(\"df_train['store_id'] \" + str(df_train['store_id'].nunique()))\n",
    "print(\"df_train['state_id'] \" + str(df_train['state_id'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering:\n",
    "\n",
    "1) Build preprocessing steps\n",
    "\n",
    "2) insert steps into preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define label encode cols, OHE cols and num cols\n",
    "target = ['revenue']\n",
    "label_cols = ['item_id']\n",
    "cat_cols = ['dept_id', 'cat_id', 'state_id', 'store_id']\n",
    "num_cols = ['datediff', 'event_cultural', 'event_national', 'event_religious', 'event_sport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate transformer for num features\n",
    "num_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate transformer for cat features\n",
    "cat_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('one_hot_encoder', OneHotEncoder(sparse=False, drop='first'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('label_encoder', LabelEncoder())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('ordinal_encoder', OrdinalEncoder())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_cols', num_transformer, num_cols),\n",
    "        ('cat_cols', cat_transformer, cat_cols),\n",
    "        ('label_cols', ordinal_transformer, label_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('linear', LinearRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "target = df_train.pop('revenue')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, target, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>datediff</th>\n",
       "      <th>event_cultural</th>\n",
       "      <th>event_national</th>\n",
       "      <th>event_religious</th>\n",
       "      <th>event_sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41997901</th>\n",
       "      <td>HOUSEHOLD_1_420</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>1405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11163141</th>\n",
       "      <td>HOUSEHOLD_1_192</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_2</td>\n",
       "      <td>CA</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31579803</th>\n",
       "      <td>HOUSEHOLD_2_215</td>\n",
       "      <td>HOUSEHOLD_2</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>WI_1</td>\n",
       "      <td>WI</td>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761899</th>\n",
       "      <td>FOODS_3_258</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_4</td>\n",
       "      <td>CA</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22323360</th>\n",
       "      <td>FOODS_1_021</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>CA_2</td>\n",
       "      <td>CA</td>\n",
       "      <td>760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043583</th>\n",
       "      <td>HOUSEHOLD_1_193</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17013587</th>\n",
       "      <td>HOBBIES_1_172</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10810330</th>\n",
       "      <td>FOODS_1_015</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>TX</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42174597</th>\n",
       "      <td>HOUSEHOLD_1_270</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>CA_3</td>\n",
       "      <td>CA</td>\n",
       "      <td>1411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21752169</th>\n",
       "      <td>HOUSEHOLD_1_040</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37588072 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  item_id      dept_id     cat_id store_id state_id  datediff  \\\n",
       "41997901  HOUSEHOLD_1_420  HOUSEHOLD_1  HOUSEHOLD     TX_1       TX      1405   \n",
       "11163141  HOUSEHOLD_1_192  HOUSEHOLD_1  HOUSEHOLD     CA_2       CA       394   \n",
       "31579803  HOUSEHOLD_2_215  HOUSEHOLD_2  HOUSEHOLD     WI_1       WI      1063   \n",
       "3761899       FOODS_3_258      FOODS_3      FOODS     CA_4       CA       151   \n",
       "22323360      FOODS_1_021      FOODS_1      FOODS     CA_2       CA       760   \n",
       "...                   ...          ...        ...      ...      ...       ...   \n",
       "2043583   HOUSEHOLD_1_193  HOUSEHOLD_1  HOUSEHOLD     CA_1       CA        95   \n",
       "17013587    HOBBIES_1_172    HOBBIES_1    HOBBIES     CA_1       CA       586   \n",
       "10810330      FOODS_1_015      FOODS_1      FOODS     TX_2       TX       382   \n",
       "42174597  HOUSEHOLD_1_270  HOUSEHOLD_1  HOUSEHOLD     CA_3       CA      1411   \n",
       "21752169  HOUSEHOLD_1_040  HOUSEHOLD_1  HOUSEHOLD     TX_1       TX       741   \n",
       "\n",
       "          event_cultural  event_national  event_religious  event_sport  \n",
       "41997901               0               0                0            0  \n",
       "11163141               0               0                0            0  \n",
       "31579803               0               0                0            0  \n",
       "3761899                0               0                0            0  \n",
       "22323360               0               0                0            0  \n",
       "...                  ...             ...              ...          ...  \n",
       "2043583                0               0                0            0  \n",
       "17013587               0               0                0            0  \n",
       "10810330               0               0                0            0  \n",
       "42174597               0               0                0            0  \n",
       "21752169               0               0                0            0  \n",
       "\n",
       "[37588072 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.40 GiB for an array with shape (37588072, 5) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\AMLA\\amla2023_at2\\notebooks\\predictive\\regression.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AMLA/amla2023_at2/notebooks/predictive/regression.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m regression_pipe\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \n\u001b[0;32m    392\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    415\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 416\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[0;32m    417\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:370\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    368\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    369\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 370\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    371\u001b[0m     cloned_transformer,\n\u001b[0;32m    372\u001b[0m     X,\n\u001b[0;32m    373\u001b[0m     y,\n\u001b[0;32m    374\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    375\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    376\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[0;32m    377\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[0;32m    378\u001b[0m )\n\u001b[0;32m    379\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 950\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    951\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:743\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    741\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m--> 743\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, y, _fit_transform_one)\n\u001b[0;32m    745\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result:\n\u001b[0;32m    746\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    664\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[0;32m    666\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    667\u001b[0m     )\n\u001b[0;32m    668\u001b[0m )\n\u001b[0;32m    669\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    671\u001b[0m         delayed(func)(\n\u001b[0;32m    672\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[0;32m    673\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m    674\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    675\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[0;32m    676\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    677\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    680\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    682\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 950\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    951\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:472\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    470\u001b[0m fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m    471\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(last_step, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 472\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39;49mfit_transform(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[0;32m    473\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    474\u001b[0m     \u001b[39mreturn\u001b[39;00m last_step\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\u001b[39m.\u001b[39mtransform(Xt)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:837\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 837\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:958\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    955\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39misnan(X)\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    957\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 958\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_ \u001b[39m=\u001b[39m _incremental_mean_and_var(\n\u001b[0;32m    959\u001b[0m             X,\n\u001b[0;32m    960\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean_,\n\u001b[0;32m    961\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvar_,\n\u001b[0;32m    962\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_samples_seen_,\n\u001b[0;32m    963\u001b[0m             sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[39m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m# if the number of samples is the same for each feature (i.e. no\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[39m# missing values)\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mptp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_seen_) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1057\u001b[0m, in \u001b[0;36m_incremental_mean_and_var\u001b[1;34m(X, last_mean, last_variance, last_sample_count, sample_weight)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1056\u001b[0m     T \u001b[39m=\u001b[39m new_sum \u001b[39m/\u001b[39m new_sample_count\n\u001b[1;32m-> 1057\u001b[0m     temp \u001b[39m=\u001b[39m X \u001b[39m-\u001b[39;49m T\n\u001b[0;32m   1058\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m         \u001b[39m# equivalent to np.nansum((X-T)**2 * sample_weight, axis=0)\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m         \u001b[39m# safer because np.float64(X*W) != np.float64(X)*np.float64(W)\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m         correction \u001b[39m=\u001b[39m _safe_accumulator_op(\n\u001b[0;32m   1062\u001b[0m             np\u001b[39m.\u001b[39mmatmul, sample_weight, np\u001b[39m.\u001b[39mwhere(X_nan_mask, \u001b[39m0\u001b[39m, temp)\n\u001b[0;32m   1063\u001b[0m         )\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.40 GiB for an array with shape (37588072, 5) and data type float64"
     ]
    }
   ],
   "source": [
    "regression_pipe.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
